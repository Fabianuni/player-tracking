{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3gLk5ZNi0Mx"
      },
      "source": [
        "# **Player detecting and tracking**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Gr0vG4jFfo"
      },
      "source": [
        "***1. Vorbereiten der Daten***\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Zuerst verbindet man sein Laufwerk mit google Drive und legt die entsprechenden Ordner an."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn_3hncSYVCT"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "print(\"mounting DRIVE...\")\n",
        "drive.mount('/content/gdrive')\n",
        "root_folder = 'PlayerYolo_darknet_Kopie' #@param {type:\"string\"}\n",
        "!ln -s /content/gdrive/My\\ Drive/$root_folder /my_drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE4Gk_MsmXII"
      },
      "source": [
        "Jetzt lädt man sich ein Fußballvideo herunter z.B. bei youtube.\n",
        "Dieses wird in den Ordner \"dataset_preparation\" gespeichert.\n",
        "In einem Unterordner werden nun Images gespeichert, die anschliesend gelabelt werden müssen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkowe0Q9mVJQ"
      },
      "outputs": [],
      "source": [
        "#aus dem Video werden images extrahiert\n",
        "import cv2\n",
        "import os\n",
        "  \n",
        "# Read the video from specified path\n",
        "cam = cv2.VideoCapture(\"/my_drive/dataset_preparation/ChelseaSalzburg.avi\") \n",
        "  \n",
        "try:\n",
        "      \n",
        "    # creating a folder named data\n",
        "    if not os.path.exists('/my_drive/dataset_preparation/images'):\n",
        "        os.makedirs('/my_drive/dataset_preparation/images')\n",
        "  \n",
        "# if not created then raise error\n",
        "except OSError:\n",
        "    print ('Error: Creating directory of data')\n",
        "  \n",
        "# frame\n",
        "currentframe = 0\n",
        "  \n",
        "while(True):\n",
        "      \n",
        "    # reading from frame\n",
        "    ret,frame = cam.read()\n",
        "  \n",
        "    if ret:\n",
        "        # if video is still left continue creating images\n",
        "        # save frame\n",
        "        name = '/my_drive/dataset_preparation/images/images' + str(currentframe) + '.jpg'\n",
        "        print ('Creating...' + name)\n",
        "  \n",
        "        # writing the extracted images\n",
        "        cv2.imwrite(name, frame)\n",
        "  \n",
        "        # increasing counter so that it will\n",
        "        # show how many frames are created\n",
        "        currentframe += 30 # i.e. at 30 fps, this advances one second\n",
        "        cam.set(1, currentframe)\n",
        "    else:\n",
        "        break\n",
        "  \n",
        "# Release all space and windows once done\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSopx6GVqsPa"
      },
      "source": [
        "Nun beginnt das labeln der einzelnen images. An diese stelle muss nun auch entschieden werden welche Klassen man verwenden will. Ich habe folgende gewählt:\n",
        "\n",
        "1. Player\n",
        "2. Referee\n",
        "3. Linesmen\n",
        "4. Ball\n",
        "5. Goalkeeper\n",
        "\n",
        "Das labeln selbst habe ich lokal ausgeführt mit LabelImg (https://github.com/tzutalin/labelImg), unter windows und anaconda.\n",
        "Die gelabelten images werden anschließend in den Ordner \"imagesLab\" gespeichert.\n",
        "Jetzt alle images und die dazugehörigen txt Dateien zippen. Die Zip- Datei muss \"obj.zip\" benannt werden und anschliesend in den Ordner \"dataset\" verschoben. \n",
        "\n",
        "Um zu sehen, ob es genug labels sind, kann man folgende Zeile ausführen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gj9ccT9CHOkm"
      },
      "outputs": [],
      "source": [
        "import glob, os\n",
        "\n",
        "TextList = []\n",
        "\n",
        "os.chdir(\"/my_drive/dataset_preparation/imagesLab\")\n",
        "for file in glob.glob(\"*.txt\"):\n",
        "    with open(file, 'r') as f:\n",
        "\t    for line in f:\n",
        "\t\t    TextList.append(line.split(None,1)[0])\n",
        "\n",
        "capacity = len(TextList)\n",
        "index = 0\n",
        "\n",
        "while index != capacity:\n",
        "\tline = TextList[index]\n",
        "\n",
        "\tfor word in line.split():\n",
        "\t\tindex += 1\n",
        "\n",
        "def count_instance():\n",
        "\n",
        "    Player = 0\n",
        "    Referee = 0\n",
        "    Linesmen = 0\n",
        "    Ball = 0\n",
        "    Goalkeeper = 0\n",
        "\n",
        "    for i in TextList:\n",
        "        if i == str(0):\n",
        "            Player += 1\n",
        "        if i == str(1):\n",
        "            Referee += 1\n",
        "        if i == str(2):\n",
        "            Linesmen += 1\n",
        "        if i == str(3):\n",
        "            Ball += 1\n",
        "        if i == str(4):\n",
        "            Goalkeeper += 1\n",
        "\n",
        "    print(\"/my_drive/dataset_preparation/imagesLab\\n\\n Player: {} \\n Referee: {} \\n Linesmen: {} \"\n",
        "          \"\\n Ball: {} \\n Goalkeeper: {}\"\n",
        "               .format(Player, Referee, Linesmen, Ball, Goalkeeper))\n",
        "\n",
        "\n",
        "count_instance()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOo8OEJ6Da5-"
      },
      "source": [
        "Jetzt wird das Archiv von darknet kopiert, mit dessen Hilfe nachher unsere Daten trainiert werden. Damit das Training schneller durchlaufen kann, sollte man die GPU verwenden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVsJinsCgxul"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/AlexeyAB/darknet\n",
        "%cd darknet\n",
        "\n",
        "OPENCV = True #@param {type:\"boolean\"}\n",
        "GPU = True #@param {type:\"boolean\"}\n",
        "CUDNN = True #@param {type:\"boolean\"}\n",
        "CUDNN_HALF = True #@param {type:\"boolean\"}\n",
        "LIBSO = False #@param {type:\"boolean\"}\n",
        "\n",
        "print(\"setting properties...\")\n",
        "if OPENCV:\n",
        "  print(\"activating OPENCV...\")\n",
        "  !sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "\n",
        "if GPU:\n",
        "  print(\"engines CUDA...\")\n",
        "  !/usr/local/cuda/bin/nvcc --version\n",
        "  \n",
        "  print(\"activating GPU...\")\n",
        "  !sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "\n",
        "if CUDNN:\n",
        "  print(\"activating CUDNN...\")\n",
        "  !sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "\n",
        "if CUDNN_HALF:\n",
        "  print(\"activating CUDNN_HALF...\")\n",
        "  !sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "\n",
        "if LIBSO: #under processing\n",
        "  print(\"activating LIBSO...\")\n",
        "  !sed -i 's/LIBSO=0/LIBSO=1/' Makefile\n",
        "\n",
        "print(\"making...\")\n",
        "!make\n",
        "\n",
        "print(\"FINISH!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrFH_i0ChBUv"
      },
      "outputs": [],
      "source": [
        "dataset_folder = 'dataset' #@param {type:\"string\"}\n",
        "\n",
        "print(\"loading dataset...\")\n",
        "!cp /my_drive/$dataset_folder/obj.zip ../\n",
        "\n",
        "print(\"unziping dataset...\")\n",
        "!unzip ../obj.zip -d data/obj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYqWia9EI-nX"
      },
      "source": [
        "Ggf. müssen nun im Ordner \"dataset\" die Dateien angepasst werden. \n",
        "- obj.name:  Hier müssen die gleichen Klassen und in der gleichen Reihenfolge wie in classes.txt im dataset_preparation vorliegen.\n",
        "- obj.data:  Hier stehen Informationen über die Klassen und das Training. Ggf. müssen auch die Pfade angepasst werden.\n",
        "- yolo-obj.cfg: Die Datei enthält wichtige Informationen zum Netzwerk, die Größe der images, Filter, Klassen usw. Für die Anpassung der Datei siehe auch [Darknet](https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects), [NET CFG Parameters](https://github.com/AlexeyAB/darknet/wiki/CFG-Parameters-in-the-%5Bnet%5D-section), [Layers CFG Parameters](https://github.com/AlexeyAB/darknet/wiki/CFG-Parameters-in-the-different-layers).\n",
        "\n",
        "Danach werden die Daten in das Projekt geladen\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60p3JImajBpD"
      },
      "outputs": [],
      "source": [
        "configuration_folder = 'configuration_files' #@param {type:\"string\"}\n",
        "\n",
        "print(\"loading yolo-obj.cfg...\")\n",
        "!cp /my_drive/$configuration_folder/yolo-obj.cfg ./cfg\n",
        "\n",
        "print(\"loading obj.names...\")\n",
        "!cp /my_drive/$configuration_folder/obj.names ./data\n",
        "\n",
        "print(\"loading obj.data...\")\n",
        "!cp /my_drive/$configuration_folder/obj.data ./data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3b0bbbf0yzF"
      },
      "source": [
        "Darknet benötigt noch eine .txt Datei, die den Pfad der einzelnen images beinhaltet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9VeORmFjoKY"
      },
      "outputs": [],
      "source": [
        "script_folder = 'py_scripts' #@param {type:\"string\"}\n",
        "\n",
        "script_file = 'generate_train.py' #@param {type:\"string\"}\n",
        "\n",
        "print(\"loading script...\")\n",
        "!cp /my_drive/$script_folder/$script_file ./\n",
        "print(\"performing script...\")\n",
        "!python $script_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX3K9tLW1Mze"
      },
      "source": [
        "Nun wird eine Yolo-Datei mit vortrainierten Gewichten geladen. Hiermit kann das Training beschleunigt werden, denn dank des Transfer-Lernens, können die vortrainierten ersten Schichten übernommen werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUwBqKK0j_5k",
        "outputId": "a56e92f2-f34e-4896-eb92-e45d8f0c26b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading pre_trained weights...\n"
          ]
        }
      ],
      "source": [
        "weights_folder = 'backup' #@param {type:\"string\"}\n",
        "\n",
        "pre_trained_weights_file = 'yolov4.conv.137' #@param {type:\"string\"}\n",
        "\n",
        "print(\"loading pre_trained weights...\")\n",
        "!cp /my_drive/$weights_folder/$pre_trained_weights_file ./"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LwqHRzn3hCu"
      },
      "source": [
        "***2. Das Training***\n",
        "\n",
        "---\n",
        "Es gibt nun die Möglichkeit die mAP-Berechnung (mittlere durchschnittliche Genauigkeit) alle 100 Iterationen anzeigen zu lassen\n",
        "\n",
        "Ebenfalls legt man nun fest, ob das Training neu gestartet wird oder fortgesetzt wird. Sollte das Skript einmal unterbrochen werden, z.B. weil die Laufzeit unterbrochen wird, kann man so das Training fortsetzten. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nLWz9UMkXZ2"
      },
      "outputs": [],
      "source": [
        "train_using_mAP = True #@param {type:\"boolean\"}\n",
        "\n",
        "option = 'RESUME TRAINING' #@param [\"START TRAINING FROM BEGINNING\", \"RESUME TRAINING\"]\n",
        "\n",
        "if option == 'START TRAINING FROM BEGINNING':\n",
        "  if train_using_mAP:\n",
        "    !./darknet detector train data/obj.data cfg/yolo-obj.cfg $pre_trained_weights_file -dont_show -map\n",
        "  else:\n",
        "    !./darknet detector train data/obj.data cfg/yolo-obj.cfg $pre_trained_weights_file -dont_show\n",
        "else:\n",
        "  if train_using_mAP:\n",
        "    !./darknet detector train data/obj.data cfg/yolo-obj.cfg /my_drive/$weights_folder/yolo-obj_last.weights -dont_show -map\n",
        "  else:\n",
        "    !./darknet detector train data/obj.data cfg/yolo-obj.cfg /my_drive/$weights_folder/yolo-obj_last.weights -dont_show\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wqg59nEP6ETt"
      },
      "source": [
        "Hat man mit mAP trainiert, können nun Graphen gespeichert werden, in dem man erst den gewünschen Bereich der Iterationen festlegt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoleYhSPkKoh"
      },
      "outputs": [],
      "source": [
        "initial_iteration_number = 100 #@param {type:\"slider\", min:100, max:10000, step:100}\n",
        "final_iteration_number = 3000 #@param {type:\"slider\", min:100, max:10000, step:100}\n",
        "\n",
        "chart_name = \"mAP-chart_iter:{}-{}.png\".format(initial_iteration_number, final_iteration_number)\n",
        "\n",
        "print(\"saving chart...\")\n",
        "\n",
        "!cp chart.png //my_drive/charts/$chart_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7q2PZEM6wcO"
      },
      "source": [
        "Hier gibt man den Namen der Gewichte ein, auf deren Grundlage die Metriken berechnet werden sollen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Q1OyrWXdWRL"
      },
      "outputs": [],
      "source": [
        "weights_name = 'yolo-obj_1000.weights' #@param {type:\"string\"}\n",
        "\n",
        "!cp /my_drive/backup/$weights_name ./\n",
        "\n",
        "!./darknet detector map data/obj.data cfg/yolo-obj.cfg $weights_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NlSPOHa7KbF"
      },
      "source": [
        "***3. Testen***\n",
        "\n",
        "---\n",
        "\n",
        "In diesem Abschnitt testen wir nun die Objekterkennung in einem Video (aber nicht das Video aus dem wir unsere Label für das Training gewonnen haben) und speichern die Ergebnisse.\n",
        "\n",
        "Sollte das Video nicht den Erwartungen entsprechen, muss noch Feintuning vorgenommen werden. Man kann z.B. ein anderes Gewicht in der oberen Kommandozeile auswählen und nochmals versuchen."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_test_folder = 'test_videos' #@param {type:\"string\"}\n",
        "input_name = 'ChelseaSalzburgclip.mp4' #@param {type:\"string\"}\n",
        "weights_type = 'yolo best' #@param [\"yolo best\", \"yolo last\"]\n",
        "predictions_folder = 'predictions' #@param {type:\"string\"}\n",
        "output_name = 'ChelseaSalzburgclip.mp4' #@param {type:\"string\"}\n",
        "prediction_version =  1 #@param {type:\"integer\"}\n",
        "\n",
        "prediction_name = \"{}_prediction_version:{}.avi\".format(output_name, prediction_version)\n",
        "\n",
        "if weights_type == \"yolo last\":\n",
        "  yolo_weights = \"yolo-obj_last.weights\"\n",
        "else:\n",
        "  yolo_weights = \"yolo-obj_best.weights\"\n",
        "\n",
        "print(\"detecting...\")\n",
        "!./darknet detector demo data/obj.data cfg/yolo-obj.cfg /my_drive/backup/$yolo_weights -dont_show /my_drive/$video_test_folder/$input_name -i 0 -out_filename prediction.avi\n",
        "\n",
        "print(\"copying prediction in Drive...\")\n",
        "!cp prediction.avi /my_drive/$predictions_folder/$prediction_name\n"
      ],
      "metadata": {
        "id": "LAXpL5uC38xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIheuZ2gAbZW"
      },
      "source": [
        "Nachdem das Testen nun erfolgreich war, kann man das nachstehende Script verwenden. Hier werden nun noch die Mannschaften anhand der Trikotsfarbe unterschieden. Trikofarben müssen ggf. angepasst werden. Hier wird weiss und rot verwendet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtrTrPjptSru"
      },
      "outputs": [],
      "source": [
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tesseract-ocr"
      ],
      "metadata": {
        "id": "BIjt-7Kx6AcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "from scipy.spatial import distance\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from google.colab.patches import cv2_imshow\n",
        "#import pytesseract\n",
        "from numpy import argmax\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "\n",
        "#please provide the paths for resources.\n",
        "yolomodel = {\"config_path\":\"/my_drive/configuration_files/yolo-obj.cfg\",\n",
        "              \"model_weights_path\":\"/my_drive/configuration_files/yolo-obj_best.weights\",\n",
        "              \"dataset_names\":\"/my_drive/configuration_files/obj.names\",\n",
        "              \"confidence_threshold\": 0.5,\n",
        "              \"threshold\":0.3\n",
        "             }\n",
        "             \n",
        "video_src = \"/my_drive/test_video/video.mp4\"\n",
        "\n",
        "temp=cv.imread(r'/my_drive/dataset_preparation/temp.jpg',0)\n",
        "ground=cv.imread('/my_drive/dataset_preparation/dst.jpg')\n",
        "out2 = cv.VideoWriter('plane.avi', cv.VideoWriter_fourcc(*\"MJPG\"), 20, (900,600))\n",
        "\n",
        "class Tracker:\n",
        "    def __init__(self, maxLost = 30):\n",
        "        self.nextObjectID = 0\n",
        "        self.objects = OrderedDict()\n",
        "        self.lost = OrderedDict()\n",
        "        self.maxLost = maxLost\n",
        "\n",
        "    def addObject(self, new_object_location):\n",
        "        self.objects[self.nextObjectID] = new_object_location\n",
        "        self.lost[self.nextObjectID] = 0\n",
        "        self.nextObjectID += 1\n",
        "\n",
        "    def removeObject(self, objectID):\n",
        "        del self.objects[objectID]\n",
        "        del self.lost[objectID]\n",
        "\n",
        "    @staticmethod\n",
        "    def getLocation(bounding_box):\n",
        "        xlt, ylt, xrb, yrb = bounding_box\n",
        "        return (int((xlt + xrb) / 2.0), int((ylt + yrb) / 2.0))\n",
        "\n",
        "    def update(self,  detections):\n",
        "        if len(detections) == 0:\n",
        "            lost_ids = list(self.lost.keys())\n",
        "\n",
        "            for objectID in lost_ids:\n",
        "                self.lost[objectID] +=1\n",
        "                if self.lost[objectID] > self.maxLost: self.removeObject(objectID)\n",
        "\n",
        "            return self.objects\n",
        "\n",
        "        new_object_locations = np.zeros((len(detections), 2), dtype=\"int\")\n",
        "\n",
        "        for (i, detection) in enumerate(detections): new_object_locations[i] = \\\n",
        "            self.getLocation(detection)\n",
        "\n",
        "        if len(self.objects)==0:\n",
        "            for i in range(0, len(detections)): self.addObject(new_object_locations[i])\n",
        "        else:\n",
        "            objectIDs = list(self.objects.keys())\n",
        "            previous_object_locations = np.array(list(self.objects.values()))\n",
        "            D = distance.cdist(previous_object_locations, new_object_locations)\n",
        "            row_idx = D.min(axis=1).argsort()\n",
        "            cols_idx = D.argmin(axis=1)[row_idx]\n",
        "            assignedRows, assignedCols = set(), set()\n",
        "\n",
        "            for (row, col) in zip(row_idx, cols_idx):\n",
        "                if row in assignedRows or col in assignedCols:\n",
        "                    continue\n",
        "\n",
        "                objectID = objectIDs[row]\n",
        "                self.objects[objectID] = new_object_locations[col]\n",
        "                self.lost[objectID] = 0\n",
        "                assignedRows.add(row)\n",
        "                assignedCols.add(col)\n",
        "\n",
        "            unassignedRows = set(range(0, D.shape[0])).difference(assignedRows)\n",
        "            unassignedCols = set(range(0, D.shape[1])).difference(assignedCols)\n",
        "\n",
        "            if D.shape[0]>=D.shape[1]:\n",
        "                for row in unassignedRows:\n",
        "                    objectID = objectIDs[row]\n",
        "                    self.lost[objectID] += 1\n",
        "                    if self.lost[objectID] > self.maxLost:\n",
        "                        self.removeObject(objectID)\n",
        "            else:\n",
        "                for col in unassignedCols:\n",
        "                    self.addObject(new_object_locations[col])\n",
        "        return self.objects\n",
        "\n",
        "net = cv.dnn.readNetFromDarknet(yolomodel[\"config_path\"], yolomodel[\"model_weights_path\"])\n",
        "labels = open(yolomodel[\"dataset_names\"]).read().strip().split(\"\\n\")\n",
        "np.random.seed(12345)\n",
        "layer_names = net.getLayerNames()\n",
        "layer_names = [layer_names[i-1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "bbox_colors = np.random.randint(0, 255, size=(len(labels), 3))\n",
        "maxLost = 5\n",
        "tracker = Tracker(maxLost = maxLost)\n",
        "cap = cv.VideoCapture(video_src)\n",
        "\n",
        "(H, W) = (None, None)\n",
        "writer = None\n",
        "\n",
        "def count_nonblack_np(img):\n",
        "    return img.any(axis=-1).sum()\n",
        "\n",
        "def color_detection(image, show = False): #<-- True for debugging\n",
        "\n",
        "    boundaries = [([17, 15, 75], [50, 56, 200]), #red\n",
        "    ([187, 169, 112], [255, 255, 255])] #white\n",
        "    \n",
        "    i = 0\n",
        "    for (lower, upper) in boundaries:\n",
        "        lower = np.array(lower, dtype = \"uint8\")\n",
        "        upper = np.array(upper, dtype = \"uint8\")\n",
        "\n",
        "        try:\n",
        "            mask = cv.inRange(image, lower, upper)\n",
        "            output = cv.bitwise_and(image, image, mask = mask)\n",
        "            tot_pix = count_nonblack_np(image)\n",
        "            color_pix = count_nonblack_np(output)\n",
        "        except:\n",
        "            print(\"strange things..\")\n",
        "            return 'not_sure'\n",
        "        ratio = color_pix/tot_pix\n",
        "        print(\"ratio is:\", ratio)\n",
        "        if ratio > 0.01 and i == 0:\n",
        "            return 'red'\n",
        "        elif ratio > 0.01 and i == 1:\n",
        "            return 'white'\n",
        "\n",
        "        i += 1\n",
        "\n",
        "        if show == True:\n",
        "            cv.imshow(\"images\", np.hstack([image, output]))\n",
        "            if cv.waitKey(0) & 0xFF == ord('q'):\n",
        "              cv.destroyAllWindows()\n",
        "    return 'not_sure'\n",
        "\n",
        "while(True):\n",
        "\n",
        "    success, image = cap.read()\n",
        "\n",
        "    if not success:\n",
        "        print(\"error!\")\n",
        "        break\n",
        "\n",
        "    if W is None or H is None: (H, W) = image.shape[:2]\n",
        "\n",
        "    blob = cv.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    detections_layer = net.forward(layer_names)\n",
        "    detections_bbox = []\n",
        "    boxes, confidences, classIDs = [], [], []\n",
        "\n",
        "    for out in detections_layer:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            classID = np.argmax(scores)\n",
        "            confidence = scores[classID]\n",
        "\n",
        "            if confidence > yolomodel['confidence_threshold']:\n",
        "                box = detection[0:4] * np.array([W, H, W, H])\n",
        "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "                x = int(centerX - (width / 2))\n",
        "                y = int(centerY - (height / 2))\n",
        "                boxes.append([x, y, int(width), int(height)])\n",
        "                confidences.append(float(confidence))\n",
        "                classIDs.append(classID)\n",
        "\n",
        "    idxs = cv.dnn.NMSBoxes(boxes, confidences, yolomodel[\"confidence_threshold\"], yolomodel[\"threshold\"])\n",
        "\n",
        "    if len(idxs)>0:\n",
        "        for i in idxs.flatten():\n",
        "            (x, y) = (boxes[i][0], boxes[i][1])\n",
        "            (w, h) = (boxes[i][2], boxes[i][3])\n",
        "            detections_bbox.append((x, y, x+w, y+h))\n",
        "\n",
        "            clr = [int(c) for c in bbox_colors[classIDs[i]]]\n",
        "\n",
        "            if labels[classIDs[i]] == \"Player\":\n",
        "                color = color_detection(image[y:y+h,x:x+w])\n",
        "                if color != 'not_sure':\n",
        "                    if color == 'red':\n",
        "                        cv.rectangle(image, (x, y), (x+w, y+h), (0, 0, 0), 2)\n",
        "                    else:\n",
        "                        cv.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)         \n",
        "\n",
        "            else:\n",
        "                cv.rectangle(image, (x, y), (x+w, y+h), clr, 2)\n",
        "\n",
        "            #playernumber = \"\"\n",
        "            \"\"\"if labels[classIDs[i]] == \"Player\":\n",
        "              hsv = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
        "              msk = cv.inRange(hsv, np.array([0, 0, 175]), np.array([179, 255, 255]))\n",
        "              krn = cv.getStructuringElement(cv.MORPH_RECT, (5, 3))\n",
        "              dlt = cv.dilate(msk, krn, iterations=1)\n",
        "              thr = 255 - cv.bitwise_and(dlt, msk)\n",
        "              playernumber = pytesseract.image_to_string(thr, config=\"--psm 10\")\"\"\"\n",
        "           \n",
        "            cv.putText(image, \"{}: {:.4f}\".format(labels[classIDs[i]], confidences[i]), (x, y-5), cv.FONT_HERSHEY_SIMPLEX, 0.5, clr, 2)\n",
        "\n",
        "    objects = tracker.update(detections_bbox)    \n",
        "\n",
        "    for (objectID, centroid) in objects.items():\n",
        "        text = \"ID {}\".format(objectID)        \n",
        "        cv.putText(image, text, (centroid[0] - 10, centroid[1] - 10), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "        cv.circle(image, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
        "    \n",
        "    \"\"\"def plane(player1,ball):\n",
        "      player1=labels[classIDs[i]] == \"Player\"\n",
        "      coptemp=ground.copy()\n",
        "      matrix=np.array([[ 2.56945407e-01,  5.90910632e-01,  1.94094537e+02],\n",
        "                     [-1.33508274e-02,  1.37658562e+00, -8.34967286e+01],\n",
        "                     [-3.41878940e-05,  1.31509536e-03,  1.00000000e+00]])\n",
        "    \n",
        "      for p in player1:\n",
        "        x=p[0]+int(p[2]/2)\n",
        "        y=p[1]+p[3]\n",
        "        pts3 = np.float32([[x,y]])\n",
        "        pts3o=cv.perspectiveTransform(pts3[None, :, :],matrix)\n",
        "        x1=int(pts3o[0][0][0])\n",
        "        y1=int(pts3o[0][0][1])\n",
        "        pp=(x1,y1)\n",
        "        if(p[4]==0):\n",
        "            cv.circle(coptemp,pp, 15, (255,0,0),-1)\n",
        "        elif p[4]==1:\n",
        "            cv.circle(coptemp,pp, 15, (255,255,255),-1)\n",
        "        elif p[4]==2:\n",
        "            #print hakm\n",
        "            #cv.circle(coptemp,pp, 15, (0,0,255),-1)\n",
        "            pass\n",
        "      if len(ball) !=0:\n",
        "        \n",
        "        xb=ball[0]+int(ball[2]/2)\n",
        "        yb=ball[1]+int(ball[3]/2)\n",
        "        pts3ball = np.float32([[xb,yb]])\n",
        "        pts3b=cv.perspectiveTransform(pts3ball[None, :, :],matrix)\n",
        "        x2=int(pts3b[0][0][0])\n",
        "        y2=int(pts3b[0][0][1])\n",
        "        pb=(x2,y2)\n",
        "        cv.circle(coptemp,pb, 15, (0,0,0),-1)\n",
        "      return coptemp\n",
        "    opr=0\n",
        "    while(cap.isOpened()):\n",
        "      ret, frame = cap.read()\n",
        "    \n",
        "      players=[]\n",
        "      ball=[]\n",
        "      if opr<310:\n",
        "        opr=opr+1\n",
        "        continue     \n",
        "    \n",
        "    if ret == True :\n",
        "        \n",
        "      copy=frame.copy()\n",
        "      gray= cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "        \n",
        "      height, width, channels = frame.shape\n",
        "        \n",
        "      blob = cv.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "\n",
        "      net.setInput(blob)\n",
        "      outs = net.forward(output_layers)\n",
        "      outs=get_players(outs, height, width)\n",
        "      for i in range(len(outs)):\n",
        "        x, y, w, h = outs[i]\n",
        "        roi = frame[y:y+h,x:x+w]\n",
        "            \n",
        "          #some frames are bad so resize function throw an error\n",
        "        try:\n",
        "            roi=cv.resize(roi, (96,96))\n",
        "        except:\n",
        "          continue\n",
        "          ym=model.predict(np.reshape(roi,(1,96,96,3)))\n",
        "          ym=argmax(ym)\n",
        "            \n",
        "          players.append([x,y,w,h,ym])\n",
        "            \n",
        "          if ym==0:\n",
        "                cv.rectangle(copy, (x, y), (x + w, y + h), (0,0,255), 2)\n",
        "          elif ym==1:\n",
        "                cv.rectangle(copy, (x, y), (x + w, y + h), (0,255,0), 2)\n",
        "          elif ym==2:\n",
        "                cv.rectangle(copy, (x, y), (x + w, y + h), (255,0,0), 2)\n",
        "            \n",
        "        \n",
        "          res = cv.matchTemplate(gray,temp,cv.TM_SQDIFF_NORMED)\n",
        "          min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
        "          if min_val < 0.05:\n",
        "            top_left = min_loc\n",
        "            bottom_right = (top_left[0] + wt, top_left[1] + ht)\n",
        "            ball.append(top_left[0])\n",
        "            ball.append(top_left[1])\n",
        "            ball.append(wt)\n",
        "            ball.append(ht)\n",
        "            cv.rectangle(copy,top_left, bottom_right, (0,255,100), 2)\n",
        "            \n",
        "        p=plane(player1, ball)\n",
        "            \n",
        "        out.write(copy)\n",
        "        out2.write(p)\n",
        "        \n",
        "        cv.imshow(p)\"\"\"\n",
        "    \n",
        "    \"\"\"src=cv.imread('/content/drive/MyDrive/PlayerYolo_darknet_OpenCV/dataset_preparation/src.jpg')\n",
        "    dst=cv.imread('/content/drive/MyDrive/PlayerYolo_darknet_OpenCV/dataset_preparation/dst.jpg')\n",
        "    #srcs=src.shape\n",
        "    #dsts=dst.shape\n",
        "    pts1 = np.float32([[940,96],[1427,395],[455,395],[943,1022]])\n",
        "    pts2 = np.float32([[450,33],[540,300],[362,302],[450,567]])\n",
        "    pts3 = np.float32([[943,395]])\n",
        "    M = cv.getPerspectiveTransform(pts1,pts2)\n",
        "    print(M)\n",
        "    pts3o=cv.perspectiveTransform(pts3[None, :, :],M)\n",
        "    x=int(pts3o[0][0][0])\n",
        "    y=int(pts3o[0][0][1])\n",
        "    p=(x,y)\n",
        "    cv.circle(dst,p, 5, (0,0,255),-1)\n",
        "    #image1=image if labels\n",
        "    #out2 = cv.VideoWriter('plane.avi',cv.VideoWriter_fourcc('M','J','P','G'), 20, (900,600))\n",
        "    #out.write(dst)\n",
        "\n",
        "   \n",
        "    out2 = cv.warpPerspective(image,M,(500, 600),flags=cv.INTER_LINEAR)\n",
        "    #gray= cv.cvtColor(plane, cv.COLOR_BGR2GRAY)\n",
        "    #plane = np.array(plane, dtype=\"uint8\")\n",
        "    #p=plane\n",
        "    #cv.imread(plane)\n",
        "        #out2.write(plane)\n",
        "    #gray= cv.cvtColor(plane, cv.COLOR_BGR2GRAY)     \n",
        "    cv2_imshow(out2)\n",
        "    #gray= cv.cvtColor(plane, cv.COLOR_BGR2GRAY) \"\"\" \n",
        "    cv2_imshow(image)\n",
        "\n",
        "\n",
        "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    if writer is None:\n",
        "        fourcc = cv.VideoWriter_fourcc(*\"MJPG\")\n",
        "        writer = cv.VideoWriter(\"/my_drive/test_video/result7.mp4\", fourcc, 30, (W, H), True)\n",
        "\n",
        "\n",
        "writer.release()\n",
        "cap.release()\n",
        "cv.destroyWindow()"
      ],
      "metadata": {
        "id": "54Y3Dpe05zx7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}